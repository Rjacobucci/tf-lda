{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/.local/share/virtualenvs/tf-lda-Y7BvcYp3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "1.7.0\n",
      "v1.7.0-3-g024aecf414\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.__git_version__)\n",
    "\n",
    "tfe.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data dimensions\n",
    "K = 3\n",
    "V = 5\n",
    "D = 100\n",
    "N = 100\n",
    "\n",
    "# set the seed\n",
    "np.random.seed(2014)\n",
    "\n",
    "# beta prior parameters\n",
    "eta = np.ones(V) * 1e-1\n",
    "\n",
    "# beta profiles\n",
    "beta = np.random.dirichlet(alpha=eta, size=K)\n",
    "\n",
    "# theta prior parameters\n",
    "alpha = np.ones(K) * 1e-1\n",
    "# alpha[0] = 10\n",
    "\n",
    "# document's prior topic allocation\n",
    "theta = np.random.dirichlet(alpha=alpha, size=D)\n",
    "\n",
    "# word's topic membership\n",
    "z = [np.random.choice(K, size=N, replace=True, p=theta[d, :]) for d in range(D)]\n",
    "z = np.vstack(z)\n",
    "\n",
    "# actual words and counts\n",
    "w = [np.array([np.random.choice(V, size=1, p=beta[k,:])[0] for k in z[d, :]]  + list(range(V))) for d in range(D)]\n",
    "nw = [np.unique(w[d], return_counts=True)[1] for d in range(D)]\n",
    "nw = np.vstack(nw)\n",
    "w = np.vstack(w)\n",
    "\n",
    "nw = tf.convert_to_tensor(nw, dtype=tf.float32)\n",
    "nw = tfe.Variable(initial_value=tf.transpose(nw),\n",
    "                 name=\"nw_vd\")\n",
    "# nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'nw_vd:0' shape=(5, 100) dtype=float32, numpy=\n",
       "array([[100.,  95.,  91.,  18.,  77.,  72.,  91.,  33.,  92.,  67.,   4.,\n",
       "        101.,  93.,  94., 101.,  87.,   1.,  59., 101.,  98.,  98.,   2.,\n",
       "         89.,  99.,  94.,  99.,  84., 100.,  97.,  39.,   1.,  99.,  99.,\n",
       "         97.,  95.,  90.,  96.,  90., 101.,  61.,   6.,  99.,  92., 100.,\n",
       "         99.,  98.,   1.,  97.,  80., 100.,  95.,  98.,  46.,   1.,  59.,\n",
       "         96.,  97.,  74.,  64.,   6.,  97.,  26.,  87.,  92.,  98.,  98.,\n",
       "         93.,  69.,  70.,  99.,  81.,  93.,  56.,  92.,  95., 101.,  96.,\n",
       "         95.,  51., 101.,   6.,  62.,  92.,   1.,  97.,  12.,  91.,   1.,\n",
       "         95.,  20., 100.,   2.,  92.,   4.,  91.,  78., 100.,  77.,  95.,\n",
       "         93.],\n",
       "       [  1.,   2.,   2.,   1.,   1.,   3.,   5.,   2.,   1.,   2.,   1.,\n",
       "          1.,   3.,   3.,   1.,   2.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   3.,   1.,   4.,   1.,   2.,   1.,   1.,   1.,   1.,\n",
       "          3.,   2.,   3.,   2.,   1.,   1.,   1.,   1.,   1.,   5.,   1.,\n",
       "          1.,   2.,   1.,   2.,   3.,   1.,   1.,   3.,   1.,   1.,   1.,\n",
       "          1.,   1.,   2.,   2.,   2.,   2.,   2.,   1.,   2.,   2.,   1.,\n",
       "          1.,   2.,   1.,   2.,   1.,   2.,   1.,   4.,   3.,   1.,   1.,\n",
       "          1.,   1.,   1.,   2.,   1.,   2.,   1.,   2.,   1.,   5.,   2.,\n",
       "          1.,   1.,   1.,   1.,   5.,   1.,   2.,   1.,   1.,   1.,   1.,\n",
       "          6.],\n",
       "       [  2.,   1.,   1.,   1.,   2.,   1.,   2.,   1.,   1.,   2.,   4.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   3.,   1.,   1.,\n",
       "          1.,   3.,   1.,   3.,   1.,   2.,   3.,   3.,   1.,   3.,   2.,\n",
       "          1.,   1.,   1.,   1.,   3.,   1.,   1.,   2.,   1.,   1.,   2.,\n",
       "          3.,   1.,   3.,   1.,   1.,   1.,   3.,   1.,   1.,   1.,   1.,\n",
       "          1.,   5.,   1.,   1.,   2.,   1.,   2.,   1.,   1.,   1.,   1.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   2.,\n",
       "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   3.,   1.,   1.,\n",
       "          1.,   2.,   2.,   1.,   1.,   1.,   1.,   3.,   2.,   2.,   1.,\n",
       "          1.],\n",
       "       [  1.,   2.,   1.,  83.,  23.,  24.,   1.,  68.,   7.,  27.,  95.,\n",
       "          1.,   1.,   1.,   1.,  13., 101.,  38.,   1.,   1.,   1.,  99.,\n",
       "         13.,   1.,   3.,   1.,  10.,   1.,   2.,  60., 100.,   1.,   2.,\n",
       "          1.,   1.,   3.,   1.,   1.,   1.,  35.,  95.,   2.,   1.,   1.,\n",
       "          1.,   1.,  99.,   1.,  16.,   2.,   1.,   1.,  56., 101.,  37.,\n",
       "          2.,   1.,  23.,  37.,  94.,   1.,  73.,  15.,   2.,   1.,   1.,\n",
       "          3.,  31.,  26.,   1.,  21.,   4.,  44.,   4.,   1.,   1.,   5.,\n",
       "          1.,  51.,   1.,  95.,  32.,   1., 101.,   1.,  88.,   3., 100.,\n",
       "          2.,  81.,   1.,  98.,   3.,  98.,   1.,  22.,   1.,  24.,   1.,\n",
       "          1.],\n",
       "       [  1.,   5.,  10.,   2.,   2.,   5.,   6.,   1.,   4.,   7.,   1.,\n",
       "          1.,   7.,   6.,   1.,   2.,   1.,   6.,   1.,   2.,   4.,   2.,\n",
       "          1.,   1.,   4.,   1.,   6.,   1.,   1.,   2.,   2.,   1.,   1.,\n",
       "          3.,   6.,   8.,   5.,  10.,   1.,   7.,   1.,   2.,   6.,   1.,\n",
       "          1.,   3.,   1.,   4.,   5.,   1.,   5.,   2.,   1.,   1.,   7.,\n",
       "          5.,   1.,   5.,   1.,   1.,   4.,   2.,   1.,   8.,   3.,   4.,\n",
       "          7.,   2.,   7.,   2.,   1.,   5.,   3.,   4.,   5.,   1.,   1.,\n",
       "          7.,   1.,   1.,   1.,   9.,   9.,   1.,   4.,   1.,   5.,   1.,\n",
       "          6.,   1.,   1.,   3.,   4.,   1.,  10.,   1.,   1.,   1.,   7.,\n",
       "          4.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize LDA parameters\n",
    "def initialize_variables(K, V, D, alpha=1e-1, eta=1e-1, seed=2014):\n",
    "    \"\"\"\n",
    "    Initialize parameters of LDA model returning adequate Tensors.\n",
    "\n",
    "    args:\n",
    "    \n",
    "        K (int): number of LDA components \n",
    "        V (int): vocabulary size\n",
    "        D (int): number of documents\n",
    "        alpha (float): hyperparameter for theta prior\n",
    "        eta (float): hyperparameter for beta prior\n",
    "       \n",
    "       \n",
    "    returns:\n",
    "    \n",
    "        eta: [V] tensor with prior parameters (alpha) for beta\n",
    "        lambda: [K, V] tensor with posterior word distribution per class\n",
    "        phi: [K, V, D] tensor with vocabulary membership per document\n",
    "        gamma: [K, D] tensor\n",
    "        \n",
    "    \"\"\"\n",
    "    tf.set_random_seed(seed)\n",
    "    eta = tfe.Variable(initial_value=tf.ones(V) * eta, \n",
    "                       name=\"eta_v\")\n",
    "    alpha = tfe.Variable(initial_value=tf.ones(K) * alpha, \n",
    "                         name=\"alpha_k\")    \n",
    "    lam = tfe.Variable(initial_value=tf.abs(tf.random_normal(shape=(K, V))), \n",
    "                       name=\"lambda_kv\")\n",
    "    \n",
    "    phi = tfe.Variable(initial_value=tf.random_normal(shape=(K, V, D)), \n",
    "                       name=\"phi_kvd\")\n",
    "    tf.assign(ref=phi, value=tf.nn.softmax(phi, axis=0))\n",
    "    \n",
    "    gamma = tfe.Variable(initial_value=tf.abs(tf.random_normal(shape=(K, D))), \n",
    "                        name=\"gamma_kd\")\n",
    "    \n",
    "    e_log_beta = tfe.Variable(initial_value=tf.abs(tf.random_normal(shape=(K, V, D))) * .0, \n",
    "                        name=\"e_log_beta_kvd\")\n",
    "    \n",
    "    e_log_theta = tfe.Variable(initial_value=tf.abs(tf.random_normal(shape=(K, V, D))) * .0, \n",
    "                        name=\"e_log_theta_kvd\")\n",
    "    \n",
    "    return eta, alpha, lam, phi, gamma, e_log_beta, e_log_theta\n",
    "\n",
    "# test\n",
    "eta, alpha, lam, phi, gamma, e_log_beta, e_log_theta = initialize_variables(K, V, D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda update\n",
    "def update_lambda(lam, eta, phi, nw):\n",
    "    \n",
    "    K = lam.shape.as_list()[0]\n",
    "    for k in range(K):\n",
    "        tf.scatter_update(ref=lam, \n",
    "                  indices=k, \n",
    "                  updates=tf.reduce_sum(tf.multiply(phi[k], nw), axis=1) + eta)\n",
    "        \n",
    "    return lam\n",
    "\n",
    "# test\n",
    "# update_lambda(lam, eta, phi, nw)\n",
    "# print(lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'gamma_kd:0' shape=(3, 100) dtype=float32, numpy=\n",
      "array([[33.179447 , 28.432518 , 12.622646 , 17.165543 , 15.577526 ,\n",
      "        10.490307 , 11.648556 , 32.405262 , 35.44801  , 46.716198 ,\n",
      "         9.907303 , 71.49604  , 45.32922  , 27.23914  , 67.28874  ,\n",
      "        49.506325 , 80.40026  , 33.695103 , 95.63079  , 70.015205 ,\n",
      "        16.508184 , 20.57544  , 20.053911 , 26.896889 , 32.449123 ,\n",
      "        16.200172 , 34.788353 , 68.103065 ,  9.126976 , 22.359228 ,\n",
      "         4.256766 , 18.665571 , 22.737452 , 61.869286 , 42.570847 ,\n",
      "         9.795437 , 14.991373 , 52.058765 , 35.303062 , 33.66349  ,\n",
      "        35.514534 , 62.23464  , 13.184516 , 84.8964   , 87.078835 ,\n",
      "        39.539482 ,  9.8654995, 59.58053  , 47.186913 ,  8.718346 ,\n",
      "        62.436123 , 50.3837   , 40.483505 , 25.55224  , 34.0292   ,\n",
      "        29.543427 ,  6.3052363, 44.445526 , 12.977353 , 18.668716 ,\n",
      "        77.82936  , 61.49327  , 38.4598   , 68.482994 , 45.963047 ,\n",
      "        95.63182  , 55.1969   , 37.85514  , 15.0718565, 40.79352  ,\n",
      "        31.472233 , 33.362446 , 22.857264 , 60.40681  , 75.502914 ,\n",
      "        51.77472  , 56.806828 , 48.250126 , 28.00236  , 17.632135 ,\n",
      "        26.48079  , 60.88403  , 23.729715 , 29.451698 , 54.593143 ,\n",
      "        11.421664 ,  9.063463 ,  8.955973 , 45.6374   , 14.291699 ,\n",
      "        37.515896 , 56.960636 , 24.985584 , 42.071983 , 41.000935 ,\n",
      "        38.35079  , 27.200687 , 51.567665 , 14.375742 ,  5.8109984],\n",
      "       [14.313186 , 62.684025 , 59.409126 , 61.227554 , 76.16197  ,\n",
      "        17.137186 , 30.851559 , 22.356226 , 38.845314 , 22.336824 ,\n",
      "        11.937884 ,  8.689513 , 43.884186 , 54.84154  , 13.376731 ,\n",
      "        21.36636  ,  7.90077  , 45.25116  ,  2.6790464,  9.441756 ,\n",
      "        83.02072  , 67.662476 , 59.379944 , 56.538647 , 11.707254 ,\n",
      "        22.467278 , 45.70648  , 22.573437 , 30.749191 , 48.32666  ,\n",
      "        14.167273 , 49.268784 , 31.317839 , 34.84559  , 35.624256 ,\n",
      "        24.24209  , 76.88125  , 42.81442  , 43.403908 , 41.327522 ,\n",
      "        13.790894 , 29.91301  , 13.677524 , 18.10674  ,  8.748406 ,\n",
      "        30.657555 , 70.90772  , 25.662413 , 34.35526  , 74.894165 ,\n",
      "        23.266092 , 31.09892  , 42.68504  , 64.510765 , 59.204903 ,\n",
      "        52.587032 , 66.7918   , 31.14974  , 45.122757 , 77.98629  ,\n",
      "        11.518945 , 16.9013   , 27.67157  ,  9.368376 ,  3.1288223,\n",
      "         4.464268 ,  9.915455 , 57.583    , 38.387375 , 24.71962  ,\n",
      "        36.194233 , 16.751156 , 51.2255   , 16.939487 , 21.884668 ,\n",
      "        45.83611  , 36.440643 , 39.041794 , 54.25267  , 11.904128 ,\n",
      "        49.776077 , 29.00714  , 63.582226 , 20.945381 , 43.58563  ,\n",
      "        15.392155 , 18.040142 , 61.239456 , 12.917989 , 75.55142  ,\n",
      "        53.05636  , 39.837097 , 42.346687 , 45.874626 , 21.718637 ,\n",
      "        50.438232 , 50.872517 , 36.98378  , 73.09963  , 20.748198 ],\n",
      "       [57.80737  , 14.183462 , 33.268227 , 26.906904 , 13.560502 ,\n",
      "        77.67251  , 62.799877 , 50.5385   , 31.006674 , 36.246975 ,\n",
      "        83.45481  , 25.114447 , 16.086596 , 23.21932  , 24.634533 ,\n",
      "        34.42731  , 16.998976 , 26.353731 ,  6.990164 , 25.843042 ,\n",
      "         5.7710886, 17.062077 , 25.86614  , 21.864468 , 61.143616 ,\n",
      "        66.63255  , 24.805168 , 14.623502 , 65.423836 , 34.614105 ,\n",
      "        86.87596  , 37.365635 , 51.244705 ,  8.585113 , 27.104883 ,\n",
      "        71.26247  , 13.427383 , 10.426818 , 26.593025 , 30.308979 ,\n",
      "        55.994576 , 13.152354 , 78.43796  ,  2.2968512,  9.472754 ,\n",
      "        35.102955 , 24.526777 , 20.057064 , 23.757826 , 21.687487 ,\n",
      "        19.597786 , 23.817389 , 22.13145  , 15.2369995, 12.065895 ,\n",
      "        23.169533 , 32.202953 , 29.704731 , 47.199894 ,  8.645002 ,\n",
      "        15.951706 , 26.905432 , 39.16863  , 27.448637 , 56.20813  ,\n",
      "         5.2039056, 40.187645 ,  9.86187  , 51.840763 , 39.78686  ,\n",
      "        37.63353  , 55.1864   , 31.21724  , 27.953695 ,  7.912415 ,\n",
      "         7.689174 , 12.052517 , 18.008081 , 23.04497  , 75.76373  ,\n",
      "        29.043137 , 15.408827 , 17.988049 , 54.902912 ,  7.1212196,\n",
      "        78.48618  , 78.196396 , 35.104565 , 46.744606 , 15.456879 ,\n",
      "        14.72775  ,  8.502259 , 37.96772  , 17.353376 , 42.58043  ,\n",
      "        16.510983 , 27.226795 , 16.748564 , 17.82463  , 78.74081  ]],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# gamma update\n",
    "def update_gamma(gamma, alpha, phi, nw):\n",
    "    \n",
    "    K = gamma.shape.as_list()[0]\n",
    "    for k in range(K):\n",
    "        tf.scatter_update(ref=gamma, \n",
    "                  indices=k, \n",
    "                  updates=tf.reduce_sum(tf.multiply(phi[k], nw), axis=0) + alpha[k])\n",
    "\n",
    "        \n",
    "    return gamma\n",
    "\n",
    "tmp = gamma.value()\n",
    "update_gamma(gamma, alpha, phi, nw)\n",
    "print(gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=132, shape=(3, 100), dtype=float32, numpy=\n",
       "array([[0.856814  , 0.17276734, 2.0289466 , 0.36276183, 1.5049754 ,\n",
       "        0.01352629, 0.8085556 , 0.05183626, 0.1407165 , 0.2526934 ,\n",
       "        1.7273577 , 0.15571633, 0.38100538, 0.26664335, 0.9372891 ,\n",
       "        0.5413353 , 1.3022376 , 0.1799982 , 1.3224765 , 0.13220988,\n",
       "        0.46405008, 1.3386966 , 1.1340383 , 0.9544467 , 1.0398598 ,\n",
       "        0.45572257, 0.41327694, 0.42305326, 1.7513535 , 1.2226332 ,\n",
       "        1.3665848 , 0.69009304, 0.19026844, 0.9641658 , 1.1776    ,\n",
       "        1.1071438 , 0.13112977, 0.8296427 , 0.79165363, 0.07314051,\n",
       "        1.2809435 , 1.5483049 , 0.44105747, 0.32301107, 0.6834025 ,\n",
       "        1.708542  , 0.08623107, 0.2677692 , 1.0648154 , 0.91856754,\n",
       "        1.791696  , 0.58421534, 0.98128223, 0.99504936, 1.5844259 ,\n",
       "        0.58608973, 0.20972344, 0.66854095, 0.9684806 , 0.9942798 ,\n",
       "        0.34617952, 1.2616568 , 0.36821425, 0.5178254 , 0.6032014 ,\n",
       "        0.25295106, 0.5769268 , 0.5076303 , 3.0258594 , 0.01671933,\n",
       "        0.65759975, 1.4400983 , 0.72903574, 0.44753274, 0.306581  ,\n",
       "        0.9649601 , 2.0758193 , 0.07931682, 0.0913691 , 0.32130983,\n",
       "        1.2582524 , 0.5447982 , 0.49283174, 1.0306956 , 1.3693771 ,\n",
       "        0.522653  , 0.71176994, 0.07558835, 1.2432694 , 0.15065473,\n",
       "        2.1940062 , 1.5684488 , 1.2134254 , 1.2639337 , 0.47438735,\n",
       "        1.0353765 , 0.77510995, 1.307206  , 2.6738834 , 1.0041995 ],\n",
       "       [0.30218256, 1.531587  , 0.38843855, 0.6294982 , 0.08004335,\n",
       "        1.373784  , 0.43551013, 0.7882019 , 1.282771  , 0.12043939,\n",
       "        0.82165176, 0.99579555, 1.0648925 , 0.798935  , 0.11279251,\n",
       "        0.8415511 , 2.0953665 , 0.23851891, 1.3490522 , 0.25984985,\n",
       "        0.470021  , 0.90162313, 1.5051732 , 0.62723076, 1.3624042 ,\n",
       "        0.86689454, 0.40423232, 1.0974534 , 2.0195618 , 0.40524113,\n",
       "        1.5220664 , 1.2017454 , 0.21543925, 0.07106953, 1.3482007 ,\n",
       "        0.12873018, 0.5404315 , 0.42295602, 0.08044315, 1.9975256 ,\n",
       "        1.6867936 , 0.7559333 , 0.25816464, 0.9088668 , 1.0503722 ,\n",
       "        1.1643885 , 1.628177  , 0.715139  , 0.7916008 , 0.5990421 ,\n",
       "        1.0500923 , 0.3663464 , 0.02048891, 0.3780402 , 2.7331867 ,\n",
       "        0.20510317, 0.45916885, 0.5263635 , 1.3115232 , 1.2843212 ,\n",
       "        0.9155544 , 0.64413935, 1.0161256 , 0.5904936 , 1.2443231 ,\n",
       "        0.11947951, 0.325826  , 0.07884961, 0.7457846 , 1.7410468 ,\n",
       "        0.18130171, 0.00737951, 1.3510817 , 2.6129313 , 1.3910831 ,\n",
       "        0.04744845, 1.9282603 , 0.05588702, 0.06307398, 0.9536268 ,\n",
       "        0.9301708 , 0.79144734, 0.47557095, 0.11905655, 0.79364973,\n",
       "        1.8787565 , 0.47477064, 0.19595565, 0.97590613, 0.10460143,\n",
       "        1.3173566 , 0.6421567 , 0.00711933, 0.5084986 , 1.3053447 ,\n",
       "        0.68444085, 0.059244  , 0.6171741 , 0.06170605, 1.0098534 ],\n",
       "       [0.75586027, 0.31541818, 1.5023085 , 0.7826398 , 0.09174243,\n",
       "        0.89958036, 0.715438  , 1.4355949 , 1.7940104 , 0.06730306,\n",
       "        0.6501585 , 1.6815329 , 1.5826735 , 0.26736948, 0.49983492,\n",
       "        0.18908036, 0.27472118, 0.37165874, 0.07324726, 0.87542355,\n",
       "        2.7648146 , 1.4850957 , 1.0914932 , 0.3079797 , 0.12082464,\n",
       "        0.6399247 , 1.4053986 , 1.2655793 , 0.16875954, 1.4814003 ,\n",
       "        1.1637396 , 1.3164532 , 0.10046536, 0.35765785, 1.5818214 ,\n",
       "        1.0807601 , 0.05280109, 1.2942514 , 1.2404304 , 1.5332966 ,\n",
       "        0.62523365, 1.7650126 , 1.0098794 , 0.9822761 , 0.00349772,\n",
       "        1.2651737 , 0.49075612, 0.4541372 , 0.16277806, 1.1089063 ,\n",
       "        0.025723  , 1.8016981 , 0.8510996 , 0.03158323, 1.5082908 ,\n",
       "        0.34409922, 1.7066221 , 0.04799074, 0.2671397 , 0.50400484,\n",
       "        1.0025127 , 1.4541929 , 1.9338974 , 0.25497139, 1.1421868 ,\n",
       "        0.1971959 , 0.23071304, 1.0208856 , 0.26911226, 0.13875245,\n",
       "        1.6067241 , 0.61561203, 0.6348207 , 0.23028512, 1.0311172 ,\n",
       "        0.9067447 , 0.5956877 , 1.1748222 , 0.8642724 , 1.107191  ,\n",
       "        0.61168027, 0.78393644, 0.615481  , 1.3173219 , 0.36875588,\n",
       "        0.5261765 , 1.2350326 , 0.2739233 , 0.53512573, 1.2558383 ,\n",
       "        0.8893851 , 1.3365593 , 0.45887238, 0.01319837, 0.46453673,\n",
       "        1.2023588 , 0.8944837 , 1.240012  , 0.5890912 , 0.23194711]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'e_log_beta_kvd:0' shape=(3, 5, 100) dtype=float32, numpy=\n",
      "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>\n",
      "<tf.Variable 'e_log_beta_kvd:0' shape=(3, 5, 100) dtype=float32, numpy=\n",
      "array([[[ -4.3613567,  -4.3613567,  -4.3613567, ...,  -4.3613567,\n",
      "          -4.3613567,  -4.3613567],\n",
      "        [ -1.004497 ,  -1.004497 ,  -1.004497 , ...,  -1.004497 ,\n",
      "          -1.004497 ,  -1.004497 ],\n",
      "        [ -3.9851837,  -3.9851837,  -3.9851837, ...,  -3.9851837,\n",
      "          -3.9851837,  -3.9851837],\n",
      "        [ -3.3059347,  -3.3059347,  -3.3059347, ...,  -3.3059347,\n",
      "          -3.3059347,  -3.3059347],\n",
      "        [ -2.936366 ,  -2.936366 ,  -2.936366 , ...,  -2.936366 ,\n",
      "          -2.936366 ,  -2.936366 ]],\n",
      "\n",
      "       [[ -2.9444265,  -2.9444265,  -2.9444265, ...,  -2.9444265,\n",
      "          -2.9444265,  -2.9444265],\n",
      "        [ -3.2798169,  -3.2798169,  -3.2798169, ...,  -3.2798169,\n",
      "          -3.2798169,  -3.2798169],\n",
      "        [ -1.8179834,  -1.8179834,  -1.8179834, ...,  -1.8179834,\n",
      "          -1.8179834,  -1.8179834],\n",
      "        [ -0.9550425,  -0.9550425,  -0.9550425, ...,  -0.9550425,\n",
      "          -0.9550425,  -0.9550425],\n",
      "        [ -4.7647123,  -4.7647123,  -4.7647123, ...,  -4.7647123,\n",
      "          -4.7647123,  -4.7647123]],\n",
      "\n",
      "       [[-17.09187  , -17.09187  , -17.09187  , ..., -17.09187  ,\n",
      "         -17.09187  , -17.09187  ],\n",
      "        [ -1.448915 ,  -1.448915 ,  -1.448915 , ...,  -1.448915 ,\n",
      "          -1.448915 ,  -1.448915 ],\n",
      "        [-15.0942   , -15.0942   , -15.0942   , ..., -15.0942   ,\n",
      "         -15.0942   , -15.0942   ],\n",
      "        [ -1.3292274,  -1.3292274,  -1.3292274, ...,  -1.3292274,\n",
      "          -1.3292274,  -1.3292274],\n",
      "        [ -2.2660816,  -2.2660816,  -2.2660816, ...,  -2.2660816,\n",
      "          -2.2660816,  -2.2660816]]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "def update_e_log_beta(e_log_beta, lam):\n",
    "    \n",
    "    K = lam.shape.as_list()[0]\n",
    "    for k in range(K):\n",
    "        tf.scatter_update(ref=e_log_beta,\n",
    "                  indices=k,\n",
    "                  updates=tf.tile(tf.expand_dims(tf.digamma(lam[k]) - tf.digamma(tf.reduce_sum(lam[k])), axis=1), multiples=[1, D]))\n",
    "    \n",
    "    return e_log_beta\n",
    "\n",
    "print(e_log_beta)\n",
    "update_e_log_beta(e_log_beta, lam);\n",
    "print(e_log_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'e_log_theta_kvd:0' shape=(3, 5, 100) dtype=float32, numpy=\n",
       "array([[[-1.165272  , -1.3222127 , -2.1566992 , ..., -0.71888995,\n",
       "         -2.0216992 , -2.9808097 ],\n",
       "        [-1.165272  , -1.3222127 , -2.1566992 , ..., -0.71888995,\n",
       "         -2.0216992 , -2.9808097 ],\n",
       "        [-1.165272  , -1.3222127 , -2.1566992 , ..., -0.71888995,\n",
       "         -2.0216992 , -2.9808097 ],\n",
       "        [-1.165272  , -1.3222127 , -2.1566992 , ..., -0.71888995,\n",
       "         -2.0216992 , -2.9808097 ],\n",
       "        [-1.165272  , -1.3222127 , -2.1566992 , ..., -0.71888995,\n",
       "         -2.0216992 , -2.9808097 ]],\n",
       "\n",
       "       [[-2.0262158 , -0.52194834, -0.5760498 , ..., -1.0551589 ,\n",
       "         -0.36708975, -1.6438904 ],\n",
       "        [-2.0262158 , -0.52194834, -0.5760498 , ..., -1.0551589 ,\n",
       "         -0.36708975, -1.6438904 ],\n",
       "        [-2.0262158 , -0.52194834, -0.5760498 , ..., -1.0551589 ,\n",
       "         -0.36708975, -1.6438904 ],\n",
       "        [-2.0262158 , -0.52194834, -0.5760498 , ..., -1.0551589 ,\n",
       "         -0.36708975, -1.6438904 ],\n",
       "        [-2.0262158 , -0.52194834, -0.5760498 , ..., -1.0551589 ,\n",
       "         -0.36708975, -1.6438904 ]],\n",
       "\n",
       "       [[-0.60361576, -2.0356474 , -1.1625597 , ..., -1.8638957 ,\n",
       "         -1.7997899 , -0.2922597 ],\n",
       "        [-0.60361576, -2.0356474 , -1.1625597 , ..., -1.8638957 ,\n",
       "         -1.7997899 , -0.2922597 ],\n",
       "        [-0.60361576, -2.0356474 , -1.1625597 , ..., -1.8638957 ,\n",
       "         -1.7997899 , -0.2922597 ],\n",
       "        [-0.60361576, -2.0356474 , -1.1625597 , ..., -1.8638957 ,\n",
       "         -1.7997899 , -0.2922597 ],\n",
       "        [-0.60361576, -2.0356474 , -1.1625597 , ..., -1.8638957 ,\n",
       "         -1.7997899 , -0.2922597 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_e_log_theta(e_log_theta, gamma):\n",
    "    \n",
    "    tf.assign(ref=e_log_theta, \n",
    "              value=tf.tile(tf.expand_dims(tf.digamma(gamma) - tf.digamma(tf.reduce_sum(gamma, axis=0)), axis=1), multiples=[1, V, 1]))\n",
    "\n",
    "    return e_log_theta\n",
    "\n",
    "update_e_log_theta(e_log_theta, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'e_log_theta_kvd:0' shape=(3, 5, 100) dtype=float32, numpy=\n",
       "array([[[-1.165272  , -1.3222127 , -2.1566992 , ..., -0.71888995,\n",
       "         -2.0216992 , -2.9808097 ],\n",
       "        [-1.165272  , -1.3222127 , -2.1566992 , ..., -0.71888995,\n",
       "         -2.0216992 , -2.9808097 ],\n",
       "        [-1.165272  , -1.3222127 , -2.1566992 , ..., -0.71888995,\n",
       "         -2.0216992 , -2.9808097 ],\n",
       "        [-1.165272  , -1.3222127 , -2.1566992 , ..., -0.71888995,\n",
       "         -2.0216992 , -2.9808097 ],\n",
       "        [-1.165272  , -1.3222127 , -2.1566992 , ..., -0.71888995,\n",
       "         -2.0216992 , -2.9808097 ]],\n",
       "\n",
       "       [[-2.0262158 , -0.52194834, -0.5760498 , ..., -1.0551589 ,\n",
       "         -0.36708975, -1.6438904 ],\n",
       "        [-2.0262158 , -0.52194834, -0.5760498 , ..., -1.0551589 ,\n",
       "         -0.36708975, -1.6438904 ],\n",
       "        [-2.0262158 , -0.52194834, -0.5760498 , ..., -1.0551589 ,\n",
       "         -0.36708975, -1.6438904 ],\n",
       "        [-2.0262158 , -0.52194834, -0.5760498 , ..., -1.0551589 ,\n",
       "         -0.36708975, -1.6438904 ],\n",
       "        [-2.0262158 , -0.52194834, -0.5760498 , ..., -1.0551589 ,\n",
       "         -0.36708975, -1.6438904 ]],\n",
       "\n",
       "       [[-0.60361576, -2.0356474 , -1.1625597 , ..., -1.8638957 ,\n",
       "         -1.7997899 , -0.2922597 ],\n",
       "        [-0.60361576, -2.0356474 , -1.1625597 , ..., -1.8638957 ,\n",
       "         -1.7997899 , -0.2922597 ],\n",
       "        [-0.60361576, -2.0356474 , -1.1625597 , ..., -1.8638957 ,\n",
       "         -1.7997899 , -0.2922597 ],\n",
       "        [-0.60361576, -2.0356474 , -1.1625597 , ..., -1.8638957 ,\n",
       "         -1.7997899 , -0.2922597 ],\n",
       "        [-0.60361576, -2.0356474 , -1.1625597 , ..., -1.8638957 ,\n",
       "         -1.7997899 , -0.2922597 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_log_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'e_log_beta_kvd:0' shape=(3, 5, 100) dtype=float32, numpy=\n",
       "array([[[ -4.3613567,  -4.3613567,  -4.3613567, ...,  -4.3613567,\n",
       "          -4.3613567,  -4.3613567],\n",
       "        [ -1.004497 ,  -1.004497 ,  -1.004497 , ...,  -1.004497 ,\n",
       "          -1.004497 ,  -1.004497 ],\n",
       "        [ -3.9851837,  -3.9851837,  -3.9851837, ...,  -3.9851837,\n",
       "          -3.9851837,  -3.9851837],\n",
       "        [ -3.3059347,  -3.3059347,  -3.3059347, ...,  -3.3059347,\n",
       "          -3.3059347,  -3.3059347],\n",
       "        [ -2.936366 ,  -2.936366 ,  -2.936366 , ...,  -2.936366 ,\n",
       "          -2.936366 ,  -2.936366 ]],\n",
       "\n",
       "       [[ -2.9444265,  -2.9444265,  -2.9444265, ...,  -2.9444265,\n",
       "          -2.9444265,  -2.9444265],\n",
       "        [ -3.2798169,  -3.2798169,  -3.2798169, ...,  -3.2798169,\n",
       "          -3.2798169,  -3.2798169],\n",
       "        [ -1.8179834,  -1.8179834,  -1.8179834, ...,  -1.8179834,\n",
       "          -1.8179834,  -1.8179834],\n",
       "        [ -0.9550425,  -0.9550425,  -0.9550425, ...,  -0.9550425,\n",
       "          -0.9550425,  -0.9550425],\n",
       "        [ -4.7647123,  -4.7647123,  -4.7647123, ...,  -4.7647123,\n",
       "          -4.7647123,  -4.7647123]],\n",
       "\n",
       "       [[-17.09187  , -17.09187  , -17.09187  , ..., -17.09187  ,\n",
       "         -17.09187  , -17.09187  ],\n",
       "        [ -1.448915 ,  -1.448915 ,  -1.448915 , ...,  -1.448915 ,\n",
       "          -1.448915 ,  -1.448915 ],\n",
       "        [-15.0942   , -15.0942   , -15.0942   , ..., -15.0942   ,\n",
       "         -15.0942   , -15.0942   ],\n",
       "        [ -1.3292274,  -1.3292274,  -1.3292274, ...,  -1.3292274,\n",
       "          -1.3292274,  -1.3292274],\n",
       "        [ -2.2660816,  -2.2660816,  -2.2660816, ...,  -2.2660816,\n",
       "          -2.2660816,  -2.2660816]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_log_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0018720626831054688\n",
      "<tf.Variable 'phi_kvd:0' shape=(3, 5, 100) dtype=float32, numpy=\n",
      "array([[[3.6447594e-01, 9.8216988e-02, 4.7535326e-02, ...,\n",
      "         2.5338078e-01, 4.4296607e-02, 5.9869461e-02],\n",
      "        [4.6129033e-01, 6.4811915e-01, 3.0940506e-01, ...,\n",
      "         7.8280282e-01, 4.2770311e-01, 9.2391737e-02],\n",
      "        [2.1311277e-01, 4.8917525e-02, 2.3025669e-02, ...,\n",
      "         1.3812724e-01, 2.1419320e-02, 2.9195052e-02],\n",
      "        [5.5261429e-02, 3.5842240e-02, 1.3987195e-02, ...,\n",
      "         9.2634402e-02, 1.5405496e-02, 6.7957784e-03],\n",
      "        [2.2242963e-01, 4.3187967e-01, 1.4157836e-01, ...,\n",
      "         5.7575411e-01, 2.3359051e-01, 3.2930043e-02]],\n",
      "\n",
      "       [[6.3552213e-01, 9.0178287e-01, 9.5246434e-01, ...,\n",
      "         7.4661893e-01, 9.5570326e-01, 9.4012803e-01],\n",
      "        [2.0040676e-02, 1.4826766e-01, 1.5446705e-01, ...,\n",
      "         5.7471670e-02, 2.2991712e-01, 3.6148567e-02],\n",
      "        [7.8688163e-01, 9.5108211e-01, 9.7697335e-01, ...,\n",
      "         8.6187208e-01, 9.7858036e-01, 9.7079843e-01],\n",
      "        [2.4518757e-01, 8.3738464e-01, 7.1314454e-01, ...,\n",
      "         6.9456363e-01, 8.4575188e-01, 2.7154094e-01],\n",
      "        [1.5109456e-02, 1.5448007e-01, 1.1051558e-01, ...,\n",
      "         6.6093192e-02, 1.9633700e-01, 2.0145046e-02]],\n",
      "\n",
      "       [[1.8914810e-06, 1.4241452e-07, 3.8016705e-07, ...,\n",
      "         2.3862324e-07, 1.6366391e-07, 2.6063733e-06],\n",
      "        [5.1866901e-01, 2.0361316e-01, 5.3612792e-01, ...,\n",
      "         1.5972558e-01, 3.4237981e-01, 8.7145966e-01],\n",
      "        [5.5969194e-06, 3.5895391e-07, 9.3191699e-07, ...,\n",
      "         6.5830221e-07, 4.0049321e-07, 6.4320211e-06],\n",
      "        [6.9955099e-01, 1.2677318e-01, 2.7286828e-01, ...,\n",
      "         2.1280201e-01, 1.3884260e-01, 7.2166324e-01],\n",
      "        [7.6246095e-01, 4.1364023e-01, 7.4790603e-01, ...,\n",
      "         3.5815272e-01, 5.7007241e-01, 9.4692492e-01]]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "def update_phi(e_log_beta, e_log_theta):\n",
    "    tf.assign(ref=phi, \n",
    "              value=e_log_beta + e_log_theta)\n",
    "    tf.assign(ref=phi, value=tf.nn.softmax(logits=phi, axis=0))\n",
    "    return phi\n",
    "\n",
    "\n",
    "update_phi(e_log_beta, e_log_theta)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=292, shape=(3, 5, 100), dtype=float32, numpy=\n",
       "array([[[9.5238099e-03, 9.0476191e-03, 8.6666662e-03, ...,\n",
       "         7.3333331e-03, 9.0476191e-03, 8.8571431e-03],\n",
       "        [9.5238094e-05, 1.9047619e-04, 1.9047619e-04, ...,\n",
       "         9.5238094e-05, 9.5238094e-05, 5.7142857e-04],\n",
       "        [1.9047619e-04, 9.5238094e-05, 9.5238094e-05, ...,\n",
       "         1.9047619e-04, 9.5238094e-05, 9.5238094e-05],\n",
       "        [9.5238094e-05, 1.9047619e-04, 9.5238094e-05, ...,\n",
       "         2.2857143e-03, 9.5238094e-05, 9.5238094e-05],\n",
       "        [9.5238094e-05, 4.7619047e-04, 9.5238094e-04, ...,\n",
       "         9.5238094e-05, 6.6666666e-04, 3.8095238e-04]],\n",
       "\n",
       "       [[9.5238099e-03, 9.0476191e-03, 8.6666662e-03, ...,\n",
       "         7.3333331e-03, 9.0476191e-03, 8.8571431e-03],\n",
       "        [9.5238094e-05, 1.9047619e-04, 1.9047619e-04, ...,\n",
       "         9.5238094e-05, 9.5238094e-05, 5.7142857e-04],\n",
       "        [1.9047619e-04, 9.5238094e-05, 9.5238094e-05, ...,\n",
       "         1.9047619e-04, 9.5238094e-05, 9.5238094e-05],\n",
       "        [9.5238094e-05, 1.9047619e-04, 9.5238094e-05, ...,\n",
       "         2.2857143e-03, 9.5238094e-05, 9.5238094e-05],\n",
       "        [9.5238094e-05, 4.7619047e-04, 9.5238094e-04, ...,\n",
       "         9.5238094e-05, 6.6666666e-04, 3.8095238e-04]],\n",
       "\n",
       "       [[9.5238099e-03, 9.0476191e-03, 8.6666662e-03, ...,\n",
       "         7.3333331e-03, 9.0476191e-03, 8.8571431e-03],\n",
       "        [9.5238094e-05, 1.9047619e-04, 1.9047619e-04, ...,\n",
       "         9.5238094e-05, 9.5238094e-05, 5.7142857e-04],\n",
       "        [1.9047619e-04, 9.5238094e-05, 9.5238094e-05, ...,\n",
       "         1.9047619e-04, 9.5238094e-05, 9.5238094e-05],\n",
       "        [9.5238094e-05, 1.9047619e-04, 9.5238094e-05, ...,\n",
       "         2.2857143e-03, 9.5238094e-05, 9.5238094e-05],\n",
       "        [9.5238094e-05, 4.7619047e-04, 9.5238094e-04, ...,\n",
       "         9.5238094e-05, 6.6666666e-04, 3.8095238e-04]]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nw_kvd = tf.tile(tf.expand_dims(nw / tf.reduce_sum(nw), axis=0), \n",
    "                 multiples=[K, 1, 1])\n",
    "nw_kvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.250828"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def elbo(phi, e_log_beta, e_log_theta, nw_kvd):\n",
    "\n",
    "    A = tf.reduce_sum(nw_kvd * phi * (e_log_beta + e_log_theta - tf.log(phi + 1e-6)))\n",
    "    \n",
    "    \n",
    "    return A.numpy()\n",
    "\n",
    "elbo(phi, e_log_beta, e_log_theta, nw_kvd)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 ELBO: -2.693914\n",
      "Iteration: 1 ELBO: -0.7925892\n",
      "Iteration: 2 ELBO: -0.7924225\n",
      "Iteration: 3 ELBO: -0.79242504\n",
      "Iteration: 4 ELBO: -0.79242784\n",
      "Iteration: 5 ELBO: -0.7924291\n",
      "Iteration: 6 ELBO: -0.7924297\n",
      "Converged!\n"
     ]
    }
   ],
   "source": [
    "seed += 1\n",
    "eta, alpha, lam, phi, gamma, e_log_beta, e_log_theta = initialize_variables(K, V, D)\n",
    "\n",
    "prev_elbo = 0.0\n",
    "next_elbo = 0.0\n",
    "iter = 0\n",
    "\n",
    "for i in range(100000):\n",
    "    \n",
    "    for j in range(100000):\n",
    "        # E-Step:\n",
    "        update_e_log_beta(e_log_beta, lam);\n",
    "        update_e_log_theta(e_log_theta, gamma);\n",
    "        update_phi(e_log_theta=e_log_theta, e_log_beta=e_log_beta)\n",
    "        gamma_prev = gamma.value()\n",
    "        update_gamma(gamma, alpha, phi, nw)\n",
    "        \n",
    "        diff = tf.reduce_mean(tf.abs(gamma_prev - gamma.value()))\n",
    "        if diff < 1e-6:\n",
    "            break\n",
    "    \n",
    "    # M-Step:\n",
    "    update_lambda(lam, eta, phi, nw)\n",
    "    \n",
    "    \n",
    "    next_elbo = elbo(phi, e_log_beta, e_log_theta, nw_kvd)\n",
    "#     next_elbo = 0.0\n",
    "    print(\"Iteration:\", iter, \"ELBO:\", next_elbo)\n",
    "    \n",
    "    diff = np.abs(next_elbo - prev_elbo)\n",
    "    if diff < 1e-6:\n",
    "        print(\"Converged!\")\n",
    "        break\n",
    "    else:\n",
    "        iter += 1\n",
    "        prev_elbo = next_elbo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.001 0.005 0.992 0.003]\n",
      " [0.99  0.001 0.009 0.    0.   ]\n",
      " [0.926 0.016 0.001 0.004 0.053]]\n",
      "[[0.901 0.018 0.013 0.037 0.031]\n",
      " [0.695 0.016 0.014 0.242 0.032]\n",
      " [0.001 0.008 0.001 0.984 0.006]]\n"
     ]
    }
   ],
   "source": [
    "print(np.round((beta), decimals=3))\n",
    "print(np.transpose(np.round(tf.transpose(lam) / tf.reduce_sum(lam, axis=1), decimals=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"NIPS_1987-2015.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw = np.array(data.iloc[:, 1:])\n",
    "nw = nw.astype('float32')\n",
    "nw = nw.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw = tf.convert_to_tensor(nw)\n",
    "# nw = nw[0:1000, :]\n",
    "nw = tf.transpose(nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "V, D = nw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_kvd = tf.tile(tf.expand_dims(nw / tf.reduce_sum(nw), axis=0), \n",
    "                 multiples=[K, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "eta, alpha, lam, phi, gamma, e_log_beta, e_log_theta = initialize_variables(K, V, D, alpha=1e-3, eta=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9235986"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elbo(phi, e_log_beta, e_log_theta, nw_kvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 10\n",
    "max_iter_e_step = 10\n",
    "\n",
    "prev_elbo = 0.0\n",
    "next_elbo = 0.0\n",
    "iter = 0\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "for i in range(max_iter):\n",
    "    \n",
    "    for j in range(max_iter_e_step):\n",
    "        # E-Step:\n",
    "        update_e_log_beta(e_log_beta, lam);\n",
    "        update_e_log_theta(e_log_theta, gamma);\n",
    "        update_phi(e_log_theta=e_log_theta, e_log_beta=e_log_beta)\n",
    "        gamma_prev = gamma.value()\n",
    "        update_gamma(gamma, alpha, phi, nw)\n",
    "        diff = tf.reduce_mean(tf.abs(gamma_prev - gamma.value()))\n",
    "        if diff < 1e-3:\n",
    "            break\n",
    "    \n",
    "    # M-Step:\n",
    "    update_lambda(lam, eta, phi, nw)\n",
    "    \n",
    "    \n",
    "    next_elbo = elbo(phi, e_log_beta, e_log_theta, nw_kvd)\n",
    "    print(\"Iteration:\", iter, \"ELBO:\", next_elbo)\n",
    "    \n",
    "    \n",
    "    diff = np.abs(next_elbo - prev_elbo)\n",
    "    if diff < 1e-6:\n",
    "        print(\"Converged!\")\n",
    "        break\n",
    "    else:\n",
    "        iter += 1\n",
    "        prev_elbo = next_elbo\n",
    "\n",
    "        \n",
    "end = time.time()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.572712027364307\n"
     ]
    }
   ],
   "source": [
    "print((end - start) / 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ELBO: -7.7598295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.009083748"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Iteration:\", iter, \"ELBO:\", next_elbo)\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=47591, shape=(10, 5811), dtype=float32, numpy=\n",
       "array([[3.10704231e-01, 4.31428969e-01, 2.57008106e-01, ...,\n",
       "        4.67069412e-07, 4.78466461e-07, 4.87802595e-07],\n",
       "       [4.87739407e-02, 2.10148886e-01, 2.10566476e-01, ...,\n",
       "        4.67069412e-07, 1.13660265e-02, 7.59115145e-02],\n",
       "       [2.11768657e-01, 4.61465305e-07, 1.36448264e-01, ...,\n",
       "        4.52919096e-01, 6.49587631e-01, 4.87802595e-07],\n",
       "       ...,\n",
       "       [1.11565702e-01, 1.27184093e-01, 1.36335418e-01, ...,\n",
       "        4.67069412e-07, 4.78466461e-07, 8.18663687e-02],\n",
       "       [1.17566949e-02, 4.61465305e-07, 8.53963968e-07, ...,\n",
       "        1.91637091e-02, 3.43658105e-02, 2.96117544e-01],\n",
       "       [1.05418310e-01, 5.26086725e-02, 9.31278169e-02, ...,\n",
       "        1.81051955e-01, 1.02145359e-01, 3.26492637e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 11463)\n",
      "(5811, 10)\n",
      "(5811,)\n",
      "(11463,)\n",
      "(11463,)\n"
     ]
    }
   ],
   "source": [
    "# topic term distribution:\n",
    "topic_term_dist = (tf.transpose(tf.transpose(lam) / tf.reduce_sum(lam, axis=1))).numpy()\n",
    "print(topic_term_dist.shape)\n",
    "\n",
    "# doc_topic_dists :array-like, shape (n_docs, n_topics)\n",
    "doc_topic_dist = tf.transpose(gamma / tf.reduce_sum(gamma, axis=0)).numpy()\n",
    "print(doc_topic_dist.shape)\n",
    "\n",
    "# # doc_lengths :array-like, shape n_docs\n",
    "doc_len = tf.reduce_sum(nw, axis=0)\n",
    "doc_len = doc_len.numpy()\n",
    "print(doc_len.shape)\n",
    "\n",
    "# # vocab :array-like, shape n_terms\n",
    "vocab = data.iloc[:, 0].values\n",
    "print(vocab.shape)\n",
    "\n",
    "# # term_frequency :array-like, shape n_terms\n",
    "term_frec = tf.reduce_sum(nw, axis=1)\n",
    "term_frec = term_frec.numpy()\n",
    "print(term_frec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/share/virtualenvs/tf-lda-Y7BvcYp3/lib/python3.6/site-packages/pyLDAvis/_prepare.py:387: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  topic_term_dists = topic_term_dists.ix[topic_order]\n"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "topics = pyLDAvis.prepare(topic_term_dist, doc_topic_dist, doc_len, vocab, term_frec)\n",
    "pyLDAvis.save_html(topics, fileobj=\"results2.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'lambda_kv:0' shape=(10, 11463) dtype=float32, numpy=\n",
       "array([[1.00000005e-03, 1.00706820e-03, 1.69346985e+02, ...,\n",
       "        1.00000005e-03, 5.43059254e+00, 1.00000005e-03],\n",
       "       [4.18568649e+01, 1.00000005e-03, 1.53377876e+01, ...,\n",
       "        1.56098795e+01, 5.63311462e+01, 4.30760193e+01],\n",
       "       [1.00000005e-03, 1.00000005e-03, 1.00000005e-03, ...,\n",
       "        1.49566793e+01, 2.13392884e-01, 1.00000005e-03],\n",
       "       ...,\n",
       "       [1.00000005e-03, 1.00000005e-03, 1.63188601e+00, ...,\n",
       "        3.66662526e+00, 9.18198490e+00, 1.00000005e-03],\n",
       "       [4.25054169e+01, 1.00000005e-03, 1.00000005e-03, ...,\n",
       "        1.00000005e-03, 1.18314829e+01, 1.53055573e+00],\n",
       "       [1.24424562e+01, 1.60802937e+01, 1.00000005e-03, ...,\n",
       "        1.00000005e-03, 1.23185318e+02, 7.23964157e+01]], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n",
      "v1.6.0-0-gd2e24b6039\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.__git_version__)\n",
    "\n",
    "tfe.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data dimensions\n",
    "K = 3\n",
    "V = 5\n",
    "D = 10000\n",
    "N = 100\n",
    "\n",
    "# set the seed\n",
    "np.random.seed(2014)\n",
    "\n",
    "# beta prior parameters\n",
    "eta = np.ones(V) * 1e-1\n",
    "\n",
    "# beta profiles\n",
    "beta = np.random.dirichlet(alpha=eta, size=K)\n",
    "\n",
    "# theta prior parameters\n",
    "alpha = np.ones(K) * 1e-1\n",
    "# alpha[0] = 10\n",
    "\n",
    "# document's prior topic allocation\n",
    "theta = np.random.dirichlet(alpha=alpha, size=D)\n",
    "\n",
    "# word's topic membership\n",
    "z = [np.random.choice(K, size=N, replace=True, p=theta[d, :]) for d in range(D)]\n",
    "z = np.vstack(z)\n",
    "\n",
    "# actual words and counts\n",
    "w = [np.array([np.random.choice(V, size=1, p=beta[k,:])[0] for k in z[d, :]]  + list(range(V))) for d in range(D)]\n",
    "nw = [np.unique(w[d], return_counts=True)[1] for d in range(D)]\n",
    "nw = np.vstack(nw)\n",
    "w = np.vstack(w)\n",
    "\n",
    "nw = tf.convert_to_tensor(nw, dtype=tf.float32)\n",
    "nw = tfe.Variable(initial_value=tf.transpose(nw),\n",
    "                 name=\"nw_vd\")\n",
    "# nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'nw_vd:0' shape=(5, 10000) dtype=float32, numpy=\n",
       "array([[ 98.,  94.,  95., ...,  61.,  92., 101.],\n",
       "       [  1.,   3.,   1., ...,   1.,   5.,   1.],\n",
       "       [  1.,   1.,   1., ...,   1.,   1.,   1.],\n",
       "       [  4.,   1.,   3., ...,  34.,   2.,   1.],\n",
       "       [  1.,   6.,   5., ...,   8.,   5.,   1.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize LDA parameters\n",
    "def initialize_variables(K, V, D, alpha=1e-1, eta=1e-1, seed=2014):\n",
    "    \"\"\"\n",
    "    Initialize parameters of LDA model returning adequate Tensors.\n",
    "\n",
    "    args:\n",
    "    \n",
    "        K (int): number of LDA components \n",
    "        V (int): vocabulary size\n",
    "        D (int): number of documents\n",
    "        alpha (float): hyperparameter for theta prior\n",
    "        eta (float): hyperparameter for beta prior\n",
    "       \n",
    "       \n",
    "    returns:\n",
    "    \n",
    "        eta: [V] tensor with prior parameters (alpha) for beta\n",
    "        lambda: [K, V] tensor with posterior word distribution per class\n",
    "        phi: [K, V, D] tensor with vocabulary membership per document\n",
    "        gamma: [K, D] tensor\n",
    "        \n",
    "    \"\"\"\n",
    "    tf.set_random_seed(seed)\n",
    "    eta = tfe.Variable(initial_value=tf.ones(V) * eta, \n",
    "                       name=\"eta_v\")\n",
    "    alpha = tfe.Variable(initial_value=tf.ones(K) * alpha, \n",
    "                         name=\"alpha_k\")    \n",
    "    lam = tfe.Variable(initial_value=tf.abs(tf.random_normal(shape=(K, V))), \n",
    "                       name=\"lambda_kv\")\n",
    "    \n",
    "    phi = tfe.Variable(initial_value=tf.random_normal(shape=(K, V, D)), \n",
    "                       name=\"phi_kvd\")\n",
    "    tf.assign(ref=phi, value=tf.nn.softmax(phi, axis=0))\n",
    "    \n",
    "    gamma = tfe.Variable(initial_value=tf.abs(tf.random_normal(shape=(K, D))), \n",
    "                        name=\"gamma_kd\")\n",
    "    \n",
    "    e_log_beta = tfe.Variable(initial_value=tf.abs(tf.random_normal(shape=(K, V, D))) * .0, \n",
    "                        name=\"e_log_beta_kvd\")\n",
    "    \n",
    "    e_log_theta = tfe.Variable(initial_value=tf.abs(tf.random_normal(shape=(K, V, D))) * .0, \n",
    "                        name=\"e_log_theta_kvd\")\n",
    "    \n",
    "    return eta, alpha, lam, phi, gamma, e_log_beta, e_log_theta\n",
    "\n",
    "# test\n",
    "eta, alpha, lam, phi, gamma, e_log_beta, e_log_theta = initialize_variables(K, V, D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda update\n",
    "def update_lambda(lam, eta, phi, nw):\n",
    "    \n",
    "    K = lam.shape.as_list()[0]\n",
    "    for k in range(K):\n",
    "        tf.scatter_update(ref=lam, \n",
    "                  indices=k, \n",
    "                  updates=tf.reduce_sum(tf.multiply(phi[k], nw), axis=1) + eta)\n",
    "        \n",
    "    return lam\n",
    "\n",
    "# test\n",
    "# update_lambda(lam, eta, phi, nw)\n",
    "# print(lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'gamma_kd:0' shape=(3, 10000) dtype=float32, numpy=\n",
      "array([[27.037819 , 23.25609  ,  7.463204 , ..., 33.399498 , 12.000949 ,\n",
      "        42.4766   ],\n",
      "       [39.71325  ,  7.5656514, 77.13596  , ..., 41.464417 , 80.972755 ,\n",
      "        20.695469 ],\n",
      "       [38.548927 , 74.47826  , 20.700846 , ..., 30.436089 , 12.326286 ,\n",
      "        42.127922 ]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# gamma update\n",
    "def update_gamma(gamma, alpha, phi, nw):\n",
    "    \n",
    "    K = gamma.shape.as_list()[0]\n",
    "    for k in range(K):\n",
    "        tf.scatter_update(ref=gamma, \n",
    "                  indices=k, \n",
    "                  updates=tf.reduce_sum(tf.multiply(phi[k], nw), axis=0) + alpha[k])\n",
    "\n",
    "        \n",
    "    return gamma\n",
    "\n",
    "tmp = gamma.value()\n",
    "update_gamma(gamma, alpha, phi, nw)\n",
    "print(gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=127, shape=(3, 10000), dtype=float32, numpy=\n",
       "array([[0.856814  , 0.17276734, 2.0289466 , ..., 2.2287955 , 0.6736742 ,\n",
       "        1.2884287 ],\n",
       "       [0.12763453, 0.48072174, 0.32087612, ..., 0.89596504, 1.4283997 ,\n",
       "        1.2293065 ],\n",
       "       [0.7794944 , 0.09269007, 2.6102738 , ..., 0.2585634 , 0.5823797 ,\n",
       "        0.7791185 ]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'e_log_beta_kvd:0' shape=(3, 5, 10000) dtype=float32, numpy=\n",
      "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>\n",
      "<tf.Variable 'e_log_beta_kvd:0' shape=(3, 5, 10000) dtype=float32, numpy=\n",
      "array([[[ -4.3613567,  -4.3613567,  -4.3613567, ...,  -4.3613567,\n",
      "          -4.3613567,  -4.3613567],\n",
      "        [ -1.004497 ,  -1.004497 ,  -1.004497 , ...,  -1.004497 ,\n",
      "          -1.004497 ,  -1.004497 ],\n",
      "        [ -3.9851837,  -3.9851837,  -3.9851837, ...,  -3.9851837,\n",
      "          -3.9851837,  -3.9851837],\n",
      "        [ -3.3059347,  -3.3059347,  -3.3059347, ...,  -3.3059347,\n",
      "          -3.3059347,  -3.3059347],\n",
      "        [ -2.9363658,  -2.9363658,  -2.9363658, ...,  -2.9363658,\n",
      "          -2.9363658,  -2.9363658]],\n",
      "\n",
      "       [[ -2.9444265,  -2.9444265,  -2.9444265, ...,  -2.9444265,\n",
      "          -2.9444265,  -2.9444265],\n",
      "        [ -3.2798169,  -3.2798169,  -3.2798169, ...,  -3.2798169,\n",
      "          -3.2798169,  -3.2798169],\n",
      "        [ -1.8179834,  -1.8179834,  -1.8179834, ...,  -1.8179834,\n",
      "          -1.8179834,  -1.8179834],\n",
      "        [ -0.9550425,  -0.9550425,  -0.9550425, ...,  -0.9550425,\n",
      "          -0.9550425,  -0.9550425],\n",
      "        [ -4.7647123,  -4.7647123,  -4.7647123, ...,  -4.7647123,\n",
      "          -4.7647123,  -4.7647123]],\n",
      "\n",
      "       [[-17.09187  , -17.09187  , -17.09187  , ..., -17.09187  ,\n",
      "         -17.09187  , -17.09187  ],\n",
      "        [ -1.4489148,  -1.4489148,  -1.4489148, ...,  -1.4489148,\n",
      "          -1.4489148,  -1.4489148],\n",
      "        [-15.094204 , -15.094204 , -15.094204 , ..., -15.094204 ,\n",
      "         -15.094204 , -15.094204 ],\n",
      "        [ -1.3292274,  -1.3292274,  -1.3292274, ...,  -1.3292274,\n",
      "          -1.3292274,  -1.3292274],\n",
      "        [ -2.2660813,  -2.2660813,  -2.2660813, ...,  -2.2660813,\n",
      "          -2.2660813,  -2.2660813]]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "def update_e_log_beta(e_log_beta, lam):\n",
    "    \n",
    "    K = lam.shape.as_list()[0]\n",
    "    for k in range(K):\n",
    "        tf.scatter_update(ref=e_log_beta,\n",
    "                  indices=k,\n",
    "                  updates=tf.tile(tf.expand_dims(tf.digamma(lam[k]) - tf.digamma(tf.reduce_sum(lam[k])), axis=1), multiples=[1, D]))\n",
    "    \n",
    "    return e_log_beta\n",
    "\n",
    "print(e_log_beta)\n",
    "update_e_log_beta(e_log_beta, lam);\n",
    "print(e_log_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'e_log_theta_kvd:0' shape=(3, 5, 10000) dtype=float32, numpy=\n",
       "array([[[-1.3734272 , -1.5271437 , -2.7105618 , ..., -1.1585617 ,\n",
       "         -2.209313  , -0.9149213 ],\n",
       "        [-1.3734272 , -1.5271437 , -2.7105618 , ..., -1.1585617 ,\n",
       "         -2.209313  , -0.9149213 ],\n",
       "        [-1.3734272 , -1.5271437 , -2.7105618 , ..., -1.1585617 ,\n",
       "         -2.209313  , -0.9149213 ],\n",
       "        [-1.3734272 , -1.5271437 , -2.7105618 , ..., -1.1585617 ,\n",
       "         -2.209313  , -0.9149213 ],\n",
       "        [-1.3734272 , -1.5271437 , -2.7105618 , ..., -1.1585617 ,\n",
       "         -2.209313  , -0.9149213 ]],\n",
       "\n",
       "       [[-0.9830153 , -2.6959803 , -0.312984  , ..., -0.9393289 ,\n",
       "         -0.2641325 , -1.6464968 ],\n",
       "        [-0.9830153 , -2.6959803 , -0.312984  , ..., -0.9393289 ,\n",
       "         -0.2641325 , -1.6464968 ],\n",
       "        [-0.9830153 , -2.6959803 , -0.312984  , ..., -0.9393289 ,\n",
       "         -0.2641325 , -1.6464968 ],\n",
       "        [-0.9830153 , -2.6959803 , -0.312984  , ..., -0.9393289 ,\n",
       "         -0.2641325 , -1.6464968 ],\n",
       "        [-0.9830153 , -2.6959803 , -0.312984  , ..., -0.9393289 ,\n",
       "         -0.2641325 , -1.6464968 ]],\n",
       "\n",
       "       [[-1.0131555 , -0.34827852, -1.6462312 , ..., -1.2529464 ,\n",
       "         -2.181435  , -0.9232621 ],\n",
       "        [-1.0131555 , -0.34827852, -1.6462312 , ..., -1.2529464 ,\n",
       "         -2.181435  , -0.9232621 ],\n",
       "        [-1.0131555 , -0.34827852, -1.6462312 , ..., -1.2529464 ,\n",
       "         -2.181435  , -0.9232621 ],\n",
       "        [-1.0131555 , -0.34827852, -1.6462312 , ..., -1.2529464 ,\n",
       "         -2.181435  , -0.9232621 ],\n",
       "        [-1.0131555 , -0.34827852, -1.6462312 , ..., -1.2529464 ,\n",
       "         -2.181435  , -0.9232621 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_e_log_theta(e_log_theta, gamma):\n",
    "    \n",
    "    tf.assign(ref=e_log_theta, \n",
    "              value=tf.tile(tf.expand_dims(tf.digamma(gamma) - tf.digamma(tf.reduce_sum(gamma, axis=0)), axis=1), multiples=[1, V, 1]))\n",
    "\n",
    "    return e_log_theta\n",
    "\n",
    "update_e_log_theta(e_log_theta, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'e_log_theta_kvd:0' shape=(3, 5, 10000) dtype=float32, numpy=\n",
       "array([[[-1.3734272 , -1.5271437 , -2.7105618 , ..., -1.1585617 ,\n",
       "         -2.209313  , -0.9149213 ],\n",
       "        [-1.3734272 , -1.5271437 , -2.7105618 , ..., -1.1585617 ,\n",
       "         -2.209313  , -0.9149213 ],\n",
       "        [-1.3734272 , -1.5271437 , -2.7105618 , ..., -1.1585617 ,\n",
       "         -2.209313  , -0.9149213 ],\n",
       "        [-1.3734272 , -1.5271437 , -2.7105618 , ..., -1.1585617 ,\n",
       "         -2.209313  , -0.9149213 ],\n",
       "        [-1.3734272 , -1.5271437 , -2.7105618 , ..., -1.1585617 ,\n",
       "         -2.209313  , -0.9149213 ]],\n",
       "\n",
       "       [[-0.9830153 , -2.6959803 , -0.312984  , ..., -0.9393289 ,\n",
       "         -0.2641325 , -1.6464968 ],\n",
       "        [-0.9830153 , -2.6959803 , -0.312984  , ..., -0.9393289 ,\n",
       "         -0.2641325 , -1.6464968 ],\n",
       "        [-0.9830153 , -2.6959803 , -0.312984  , ..., -0.9393289 ,\n",
       "         -0.2641325 , -1.6464968 ],\n",
       "        [-0.9830153 , -2.6959803 , -0.312984  , ..., -0.9393289 ,\n",
       "         -0.2641325 , -1.6464968 ],\n",
       "        [-0.9830153 , -2.6959803 , -0.312984  , ..., -0.9393289 ,\n",
       "         -0.2641325 , -1.6464968 ]],\n",
       "\n",
       "       [[-1.0131555 , -0.34827852, -1.6462312 , ..., -1.2529464 ,\n",
       "         -2.181435  , -0.9232621 ],\n",
       "        [-1.0131555 , -0.34827852, -1.6462312 , ..., -1.2529464 ,\n",
       "         -2.181435  , -0.9232621 ],\n",
       "        [-1.0131555 , -0.34827852, -1.6462312 , ..., -1.2529464 ,\n",
       "         -2.181435  , -0.9232621 ],\n",
       "        [-1.0131555 , -0.34827852, -1.6462312 , ..., -1.2529464 ,\n",
       "         -2.181435  , -0.9232621 ],\n",
       "        [-1.0131555 , -0.34827852, -1.6462312 , ..., -1.2529464 ,\n",
       "         -2.181435  , -0.9232621 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_log_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'e_log_beta_kvd:0' shape=(3, 5, 10000) dtype=float32, numpy=\n",
       "array([[[ -4.3613567,  -4.3613567,  -4.3613567, ...,  -4.3613567,\n",
       "          -4.3613567,  -4.3613567],\n",
       "        [ -1.004497 ,  -1.004497 ,  -1.004497 , ...,  -1.004497 ,\n",
       "          -1.004497 ,  -1.004497 ],\n",
       "        [ -3.9851837,  -3.9851837,  -3.9851837, ...,  -3.9851837,\n",
       "          -3.9851837,  -3.9851837],\n",
       "        [ -3.3059347,  -3.3059347,  -3.3059347, ...,  -3.3059347,\n",
       "          -3.3059347,  -3.3059347],\n",
       "        [ -2.9363658,  -2.9363658,  -2.9363658, ...,  -2.9363658,\n",
       "          -2.9363658,  -2.9363658]],\n",
       "\n",
       "       [[ -2.9444265,  -2.9444265,  -2.9444265, ...,  -2.9444265,\n",
       "          -2.9444265,  -2.9444265],\n",
       "        [ -3.2798169,  -3.2798169,  -3.2798169, ...,  -3.2798169,\n",
       "          -3.2798169,  -3.2798169],\n",
       "        [ -1.8179834,  -1.8179834,  -1.8179834, ...,  -1.8179834,\n",
       "          -1.8179834,  -1.8179834],\n",
       "        [ -0.9550425,  -0.9550425,  -0.9550425, ...,  -0.9550425,\n",
       "          -0.9550425,  -0.9550425],\n",
       "        [ -4.7647123,  -4.7647123,  -4.7647123, ...,  -4.7647123,\n",
       "          -4.7647123,  -4.7647123]],\n",
       "\n",
       "       [[-17.09187  , -17.09187  , -17.09187  , ..., -17.09187  ,\n",
       "         -17.09187  , -17.09187  ],\n",
       "        [ -1.4489148,  -1.4489148,  -1.4489148, ...,  -1.4489148,\n",
       "          -1.4489148,  -1.4489148],\n",
       "        [-15.094204 , -15.094204 , -15.094204 , ..., -15.094204 ,\n",
       "         -15.094204 , -15.094204 ],\n",
       "        [ -1.3292274,  -1.3292274,  -1.3292274, ...,  -1.3292274,\n",
       "          -1.3292274,  -1.3292274],\n",
       "        [ -2.2660813,  -2.2660813,  -2.2660813, ...,  -2.2660813,\n",
       "          -2.2660813,  -2.2660813]]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_log_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012933015823364258\n",
      "<tf.Variable 'phi_kvd:0' shape=(3, 5, 10000) dtype=float32, numpy=\n",
      "array([[[1.4095956e-01, 4.3829095e-01, 2.1572903e-02, ...,\n",
      "         1.6298778e-01, 3.3500813e-02, 3.3506691e-01],\n",
      "        [4.8282588e-01, 3.2089731e-01, 2.5070122e-01, ...,\n",
      "         5.8431685e-01, 4.2049536e-01, 5.9336036e-01],\n",
      "        [7.1916632e-02, 2.6925978e-01, 1.0304886e-02, ...,\n",
      "         8.4213004e-02, 1.6105130e-02, 1.9222322e-01],\n",
      "        [3.7234083e-02, 3.6065232e-02, 7.2814878e-03, ...,\n",
      "         4.8458524e-02, 1.2219872e-02, 7.5708210e-02],\n",
      "        [2.4752221e-01, 1.3505588e-01, 1.1857255e-01, ...,\n",
      "         3.3570617e-01, 2.4189721e-01, 3.3157957e-01]],\n",
      "\n",
      "       [[8.5903984e-01, 5.6170487e-01, 9.7842681e-01, ...,\n",
      "         8.3701181e-01, 9.6649909e-01, 6.6493213e-01],\n",
      "        [7.3313750e-02, 1.0246790e-02, 2.8330383e-01, ...,\n",
      "         7.4765489e-02, 3.0226198e-01, 2.9338680e-02],\n",
      "        [9.2808187e-01, 7.3072714e-01, 9.8969460e-01, ...,\n",
      "         9.1578579e-01, 9.8389465e-01, 8.0777389e-01],\n",
      "        [5.7739609e-01, 1.1761126e-01, 8.4033912e-01, ...,\n",
      "         6.3322979e-01, 8.9707190e-01, 3.8229904e-01],\n",
      "        [5.8766138e-02, 6.7430059e-03, 2.0950684e-01, ...,\n",
      "         6.7163005e-02, 2.7187613e-01, 2.5634671e-02]],\n",
      "\n",
      "       [[5.9809111e-07, 4.2164397e-06, 1.8507599e-07, ...,\n",
      "         4.3890728e-07, 1.0194628e-07, 9.8337239e-07],\n",
      "        [4.4386038e-01, 6.6885591e-01, 4.6599495e-01, ...,\n",
      "         3.4091765e-01, 2.7724275e-01, 3.7730104e-01],\n",
      "        [1.5442140e-06, 1.3108713e-05, 4.4739392e-07, ...,\n",
      "         1.1476309e-06, 2.4801940e-07, 2.8549441e-06],\n",
      "        [3.8536978e-01, 8.4632349e-01, 1.5237939e-01, ...,\n",
      "         3.1831166e-01, 9.0708248e-02, 5.4199278e-01],\n",
      "        [6.9371170e-01, 8.5820103e-01, 6.7192066e-01, ...,\n",
      "         5.9713089e-01, 4.8622668e-01, 6.4278573e-01]]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "def update_phi(e_log_beta, e_log_theta):\n",
    "    tf.assign(ref=phi, \n",
    "              value=e_log_beta + e_log_theta)\n",
    "    tf.assign(ref=phi, value=tf.nn.softmax(logits=phi, axis=0))\n",
    "    return phi\n",
    "\n",
    "\n",
    "update_phi(e_log_beta, e_log_theta)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=312, shape=(3, 5, 10000), dtype=float32, numpy=\n",
       "array([[[9.3333336e-05, 8.9523812e-05, 9.0476191e-05, ...,\n",
       "         5.8095236e-05, 8.7619046e-05, 9.6190473e-05],\n",
       "        [9.5238096e-07, 2.8571428e-06, 9.5238096e-07, ...,\n",
       "         9.5238096e-07, 4.7619046e-06, 9.5238096e-07],\n",
       "        [9.5238096e-07, 9.5238096e-07, 9.5238096e-07, ...,\n",
       "         9.5238096e-07, 9.5238096e-07, 9.5238096e-07],\n",
       "        [3.8095238e-06, 9.5238096e-07, 2.8571428e-06, ...,\n",
       "         3.2380951e-05, 1.9047619e-06, 9.5238096e-07],\n",
       "        [9.5238096e-07, 5.7142856e-06, 4.7619046e-06, ...,\n",
       "         7.6190477e-06, 4.7619046e-06, 9.5238096e-07]],\n",
       "\n",
       "       [[9.3333336e-05, 8.9523812e-05, 9.0476191e-05, ...,\n",
       "         5.8095236e-05, 8.7619046e-05, 9.6190473e-05],\n",
       "        [9.5238096e-07, 2.8571428e-06, 9.5238096e-07, ...,\n",
       "         9.5238096e-07, 4.7619046e-06, 9.5238096e-07],\n",
       "        [9.5238096e-07, 9.5238096e-07, 9.5238096e-07, ...,\n",
       "         9.5238096e-07, 9.5238096e-07, 9.5238096e-07],\n",
       "        [3.8095238e-06, 9.5238096e-07, 2.8571428e-06, ...,\n",
       "         3.2380951e-05, 1.9047619e-06, 9.5238096e-07],\n",
       "        [9.5238096e-07, 5.7142856e-06, 4.7619046e-06, ...,\n",
       "         7.6190477e-06, 4.7619046e-06, 9.5238096e-07]],\n",
       "\n",
       "       [[9.3333336e-05, 8.9523812e-05, 9.0476191e-05, ...,\n",
       "         5.8095236e-05, 8.7619046e-05, 9.6190473e-05],\n",
       "        [9.5238096e-07, 2.8571428e-06, 9.5238096e-07, ...,\n",
       "         9.5238096e-07, 4.7619046e-06, 9.5238096e-07],\n",
       "        [9.5238096e-07, 9.5238096e-07, 9.5238096e-07, ...,\n",
       "         9.5238096e-07, 9.5238096e-07, 9.5238096e-07],\n",
       "        [3.8095238e-06, 9.5238096e-07, 2.8571428e-06, ...,\n",
       "         3.2380951e-05, 1.9047619e-06, 9.5238096e-07],\n",
       "        [9.5238096e-07, 5.7142856e-06, 4.7619046e-06, ...,\n",
       "         7.6190477e-06, 4.7619046e-06, 9.5238096e-07]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nw_kvd = tf.tile(tf.expand_dims(nw / tf.reduce_sum(nw), axis=0), \n",
    "                 multiples=[K, 1, 1])\n",
    "nw_kvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.105609"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def elbo(phi, e_log_beta, e_log_theta, nw_kvd):\n",
    "\n",
    "    A = tf.reduce_sum(nw_kvd * phi * (e_log_beta + e_log_theta - tf.log(phi + 1e-6)))\n",
    "    \n",
    "    \n",
    "    return A.numpy()\n",
    "\n",
    "elbo(phi, e_log_beta, e_log_theta, nw_kvd)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-7515b5663dd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# E-Step:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mupdate_e_log_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_log_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mupdate_e_log_theta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_log_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mupdate_phi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_log_theta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me_log_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_log_beta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me_log_beta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-828f5896ca9e>\u001b[0m in \u001b[0;36mupdate_e_log_beta\u001b[0;34m(e_log_beta, lam)\u001b[0m\n\u001b[1;32m      5\u001b[0m         tf.scatter_update(ref=e_log_beta,\n\u001b[1;32m      6\u001b[0m                   \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                   updates=tf.tile(tf.expand_dims(tf.digamma(lam[k]) - tf.digamma(tf.reduce_sum(lam[k])), axis=1), multiples=[1, D]))\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0me_log_beta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/LDA-pHQnYWLy/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtile\u001b[0;34m(input, multiples, name)\u001b[0m\n\u001b[1;32m   5596\u001b[0m     \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tmultiples\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tmultiples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5597\u001b[0m     _result = _execute.execute(b\"Tile\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 5598\u001b[0;31m                                ctx=_ctx, name=name)\n\u001b[0m\u001b[1;32m   5599\u001b[0m   _execute.record_gradient(\n\u001b[1;32m   5600\u001b[0m       \"Tile\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[0;32m~/.local/share/virtualenvs/LDA-pHQnYWLy/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed += 1\n",
    "eta, alpha, lam, phi, gamma, e_log_beta, e_log_theta = initialize_variables(K, V, D)\n",
    "\n",
    "prev_elbo = 0.0\n",
    "next_elbo = 0.0\n",
    "iter = 0\n",
    "\n",
    "for i in range(100000):\n",
    "    \n",
    "    for j in range(100000):\n",
    "        # E-Step:\n",
    "        update_e_log_beta(e_log_beta, lam);\n",
    "        update_e_log_theta(e_log_theta, gamma);\n",
    "        update_phi(e_log_theta=e_log_theta, e_log_beta=e_log_beta)\n",
    "        gamma_prev = gamma.value()\n",
    "        update_gamma(gamma, alpha, phi, nw)\n",
    "        \n",
    "        diff = tf.reduce_mean(tf.abs(gamma_prev - gamma.value()))\n",
    "        if diff < 1e-6:\n",
    "            break\n",
    "    \n",
    "    # M-Step:\n",
    "    update_lambda(lam, eta, phi, nw)\n",
    "    \n",
    "    \n",
    "    next_elbo = elbo(phi, e_log_beta, e_log_theta, nw_kvd)\n",
    "#     next_elbo = 0.0\n",
    "    print(\"Iteration:\", iter, \"ELBO:\", next_elbo)\n",
    "    \n",
    "    diff = np.abs(next_elbo - prev_elbo)\n",
    "    if diff < 1e-6:\n",
    "        print(\"Converged!\")\n",
    "        break\n",
    "    else:\n",
    "        iter += 1\n",
    "        prev_elbo = next_elbo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.001 0.005 0.992 0.003]\n",
      " [0.99  0.001 0.009 0.    0.   ]\n",
      " [0.926 0.016 0.001 0.004 0.053]]\n",
      "[[0.875 0.018 0.014 0.058 0.035]\n",
      " [0.629 0.015 0.014 0.315 0.027]\n",
      " [0.    0.01  0.014 0.964 0.012]]\n"
     ]
    }
   ],
   "source": [
    "print(np.round((beta), decimals=3))\n",
    "print(np.transpose(np.round(tf.transpose(lam) / tf.reduce_sum(lam, axis=1), decimals=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lambda_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c7d8b6eed568>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# topic term distribution:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtopic_term_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtopic_term_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# doc_topic_dists :array-like, shape (n_docs, n_topics)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lambda_' is not defined"
     ]
    }
   ],
   "source": [
    "# topic term distribution:\n",
    "topic_term_dist = np.round(np.vstack([(lam / tf.reduce_sum(lam)).numpy()  for lam in lambda_]), decimals=3)\n",
    "topic_term_dist\n",
    "\n",
    "# doc_topic_dists :array-like, shape (n_docs, n_topics)\n",
    "doc_topic_dist = tf.stack([tf.reshape(g_k, shape=(1000, )) for g_k in gamma], axis=1)\n",
    "doc_topic_dist = doc_topic_dist / tf.reduce_sum(doc_topic_dist, axis=1, keep_dims=True)\n",
    "doc_topic_dist = doc_topic_dist.numpy()\n",
    "\n",
    "# doc_lengths :array-like, shape n_docs\n",
    "doc_len = tf.reduce_sum(nw, axis=1)\n",
    "doc_len = doc_len.numpy()\n",
    "\n",
    "# vocab :array-like, shape n_terms\n",
    "vocab = np.array(list(range(V)))\n",
    "\n",
    "# term_frequency :array-like, shape n_terms\n",
    "term_frec = tf.reduce_sum(nw, axis=0)\n",
    "term_frec = term_frec.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"NIPS_1987-2015.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw = np.array(data.iloc[:, 1:])\n",
    "nw = nw.astype('float32')\n",
    "nw = nw.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw = tf.convert_to_tensor(nw)\n",
    "nw = nw[0:100, 0:1000]\n",
    "nw = tf.transpose(nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "V, D = nw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=177490, shape=(10, 1000, 100), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nw_kvd = tf.tile(tf.expand_dims(nw / tf.reduce_sum(nw), axis=0), \n",
    "                 multiples=[K, 1, 1])\n",
    "nw_kvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 ELBO: -7.432144\n",
      "Iteration: 1 ELBO: -5.433588\n",
      "Iteration: 2 ELBO: -5.341462\n",
      "Iteration: 3 ELBO: -5.2919736\n",
      "Iteration: 4 ELBO: -5.263893\n",
      "Iteration: 5 ELBO: -5.2484136\n",
      "Iteration: 6 ELBO: -5.2394495\n",
      "Iteration: 7 ELBO: -5.2338495\n",
      "Iteration: 8 ELBO: -5.2302885\n",
      "Iteration: 9 ELBO: -5.2278996\n",
      "Iteration: 10 ELBO: -5.2259912\n",
      "Iteration: 11 ELBO: -5.2249517\n",
      "Iteration: 12 ELBO: -5.2242002\n",
      "Iteration: 13 ELBO: -5.2236214\n",
      "Iteration: 14 ELBO: -5.2231464\n",
      "Iteration: 15 ELBO: -5.222804\n",
      "Iteration: 16 ELBO: -5.222607\n",
      "Iteration: 17 ELBO: -5.2224836\n",
      "Iteration: 18 ELBO: -5.2223663\n",
      "Iteration: 19 ELBO: -5.222261\n",
      "Iteration: 20 ELBO: -5.222167\n",
      "Iteration: 21 ELBO: -5.2220936\n",
      "Iteration: 22 ELBO: -5.222032\n",
      "Iteration: 23 ELBO: -5.2220173\n",
      "Iteration: 24 ELBO: -5.2219954\n",
      "Iteration: 25 ELBO: -5.2219872\n",
      "Iteration: 26 ELBO: -5.221991\n",
      "Iteration: 27 ELBO: -5.2219872\n",
      "Iteration: 28 ELBO: -5.221985\n",
      "Iteration: 29 ELBO: -5.2219744\n",
      "Iteration: 30 ELBO: -5.2219625\n",
      "Iteration: 31 ELBO: -5.2219877\n",
      "Iteration: 32 ELBO: -5.222019\n",
      "Iteration: 33 ELBO: -5.2220297\n",
      "Iteration: 34 ELBO: -5.2220325\n",
      "Iteration: 35 ELBO: -5.2220254\n",
      "Iteration: 36 ELBO: -5.222\n",
      "Iteration: 37 ELBO: -5.2219734\n",
      "Iteration: 38 ELBO: -5.22196\n",
      "Iteration: 39 ELBO: -5.22196\n",
      "Converged!\n",
      "33.650720834732056\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "eta, alpha, lam, phi, gamma, e_log_beta, e_log_theta = initialize_variables(K, V, D)\n",
    "\n",
    "prev_elbo = 0.0\n",
    "next_elbo = 0.0\n",
    "iter = 0\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "for i in range(10000):\n",
    "    \n",
    "    for j in range(1000000):\n",
    "        # E-Step:\n",
    "        update_e_log_beta(e_log_beta, lam);\n",
    "        update_e_log_theta(e_log_theta, gamma);\n",
    "        update_phi(e_log_theta=e_log_theta, e_log_beta=e_log_beta)\n",
    "        gamma_prev = gamma.value()\n",
    "        update_gamma(gamma, alpha, phi, nw)\n",
    "        \n",
    "        diff = tf.reduce_mean(tf.abs(gamma_prev - gamma.value()))\n",
    "        if diff < 1e-3:\n",
    "            break\n",
    "    \n",
    "    # M-Step:\n",
    "    update_lambda(lam, eta, phi, nw)\n",
    "    \n",
    "    \n",
    "    next_elbo = elbo(phi, e_log_beta, e_log_theta, nw_kvd)\n",
    "    print(\"Iteration:\", iter, \"ELBO:\", next_elbo)\n",
    "    \n",
    "    diff = np.abs(next_elbo - prev_elbo)\n",
    "    if diff < 1e-6:\n",
    "        print(\"Converged!\")\n",
    "        break\n",
    "    else:\n",
    "        iter += 1\n",
    "        prev_elbo = next_elbo\n",
    "\n",
    "        \n",
    "end = time.time()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'lambda_kv:0' shape=(10, 1000) dtype=float32, numpy=\n",
       "array([[0.1       , 0.1       , 0.1       , ..., 0.1       , 0.10013366,\n",
       "        0.10001303],\n",
       "       [0.1       , 0.1       , 0.1       , ..., 0.1       , 0.10004404,\n",
       "        0.10002226],\n",
       "       [0.1       , 0.1       , 0.1       , ..., 0.1       , 7.044639  ,\n",
       "        0.1       ],\n",
       "       ...,\n",
       "       [0.1       , 0.1       , 0.1       , ..., 0.1       , 0.1       ,\n",
       "        0.1       ],\n",
       "       [0.1       , 0.1       , 0.1       , ..., 0.1       , 0.1       ,\n",
       "        0.10000306],\n",
       "       [0.1       , 0.1       , 0.1       , ..., 0.1       , 0.10000444,\n",
       "        3.0999494 ]], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
